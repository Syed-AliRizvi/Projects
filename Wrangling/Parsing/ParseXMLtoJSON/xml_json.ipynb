{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 3 in Assessment 1\n",
    "#### Student Name: Syed Ali Alim Rizvi\n",
    "#### Student ID: 28984773\n",
    "\n",
    "Date: 08/04/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment here, e.g.,:\n",
    "* re: for regexes. \n",
    "* json: for file to be converted to json output file.\n",
    "\n",
    "<font size=3, color=\"red\"> Note: this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. It is important to make sure the logic of how you finish the assessment is clearly shown in this notebook! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib for regular expression\n",
    "# !pip install re\n",
    "# !pip install json\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse XML File\n",
    "\n",
    "In this section, you can write your python scripts to parse the correspondiing file.\n",
    "You should \n",
    "* write proper notes for all code block in this notebook using the Markdown cells\n",
    "* provide proper comment in your scripts\n",
    "* run all cells to make sure scripts are runable. If the scripts cannot be run by the assessors, they will not be assessed and zero mark will be given to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "xml = open('australian-sport-thesaurus-student.xml', 'r', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regexes and a bit of tweaking\n",
    "\n",
    "Since each element is within one line hence the text between the tags can be extracted using a regex that could be applied to that line. In this implementation we make use of the group feature in regexes to extract text from that specific group as the text for our variable. The regexes used as shown further below make use of the the amount of spaces before each tag aswell as the name of the tags. \n",
    "\n",
    "A seperate regex is created to extract text from each element i.e. a seperate regex for title, description, related terms etc. \n",
    "\n",
    "Once applied it can be seen that one of the elements of description is stored in seperate lines hence the regex created does not work as it also tries to match the end of the tag within the line. This issue is further explained below.\n",
    "\n",
    "The description element that is spread across multiple lines is as follows.\n",
    "\n",
    "```\n",
    "<Description>Athlete with one of a wide range of visual impairment (Blindness).\n",
    "\n",
    "Suggest: Use for [non preferred term] Blind Athlete</Description>\n",
    "```\n",
    "\n",
    "due to the fact that one line for <Description> doesnt end with the tag. hence we create two new regexes to store the description for the first error line and another regex to store the description for the second error line then concatinate the two results to store the corrected description in the final dictionary.\n",
    "   \n",
    "```python\n",
    "desc = re.compile(r'^[ ]{4}<Description>(.[^>]*)</Description>$') #for normal desc\n",
    "desc_error_start = re.compile(r'^[ ]{4}<Description>(.[^>]*)$') #for broken  desc start\n",
    "desc_error_end = re.compile(r'^(.[^>]*)</Description>$') #for broken desc end\n",
    "```\n",
    "\n",
    "since in the regex `(.[^>]*)` is gready hence to avoid it from including `<Description>` in the text we add a `[^>]` check so that it does not include it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regexes to use to extract\n",
    "desc = re.compile(r'^[ ]{4}<Description>(.[^>]*)</Description>$') #for normal desc\n",
    "desc_error_start = re.compile(r'^[ ]{4}<Description>(.[^>]*)$') #for broken  desc start\n",
    "desc_error_end = re.compile(r'^(.[^>]*)</Description>$') #for broken desc end\n",
    "title = re.compile(r'^[ ]{4}<Title>(.*)</Title>$') #for title\n",
    "rel_title = re.compile(r'^[ ]{8}<Title>(.*)</Title>$') #for related title\n",
    "rel_relationship = re.compile(r'^[ ]{8}<Relationship>(.*)</Relationship>$') #for related relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open excel file to read using utf-8 encoding\n",
    "xml = open('australian-sport-thesaurus-student.xml', 'r', encoding='utf-8')\n",
    "\n",
    "dic = {'thesaurus' : []} #dictionary to hold final output\n",
    "new_rec = {} #dictionary to store current record attributes\n",
    "sorted_new_rec = {} #a dictionary to store sorted values of new_rec\n",
    "\n",
    "\n",
    "sub_dic = False # a check to see whether the title attribute is for the subrecord or for the original\n",
    "\n",
    "#loop over each line in exml\n",
    "for line in xml:\n",
    "    \n",
    "    #check if a new data record starts; if yes put the rec attributes in final dictionary\n",
    "    if line.startswith('  <Term>'):\n",
    "        if new_rec: #if there has been a previous record put in the record after sorting the dictionary\n",
    "            for key in sorted(new_rec):\n",
    "                sorted_new_rec[key] = new_rec[key]\n",
    "            dic['thesaurus'].append(sorted_new_rec)\n",
    "            #empty both dictionaries for the next record attributes\n",
    "            new_rec = {}\n",
    "            sorted_new_rec = {}\n",
    "        continue\n",
    "    \n",
    "    #if the line has the tag title check if the sub record tick is True or false. \n",
    "    elif '<Title>' in line:\n",
    "        if sub_dic == False:\n",
    "            rec_title = title.match(line)\n",
    "            new_rec['Title'] = rec_title.group(1) \n",
    "        else:#if not subrecord add to rec dic as original title\n",
    "            rec_rel_title = rel_title.match(line)\n",
    "            #since related terms is a list and only has one element(dictionary) we use the index of 0 to get the dic and pass the key\n",
    "            new_rec['RelatedTerms'][0]['Title'] = rec_rel_title.group(1) #if subrecord add to Related terms title in sub dic\n",
    "    \n",
    "    elif '<Description>' in line or '</Description>' in line: #check if description in line (some description elements dont include both tags)\n",
    "        rec_desc = desc.match(line)\n",
    "        try:\n",
    "            new_rec['Description'] = rec_desc.group(1) #if tag is normal put in dictionary\n",
    "        except AttributeError: #if error tag then\n",
    "            if line.startswith('    <Description>'): #if starting of the error tag\n",
    "                rec_desc = desc_error_start.match(line)\n",
    "                desc_line = rec_desc.group(1)\n",
    "                desc_line = desc_line.strip() #store the first part of the tag\n",
    "            elif line.startswith('Suggest'): #if ending of the error tag\n",
    "                rec_desc = desc_error_end.match(line)\n",
    "                desc_line = desc_line + ' ' + rec_desc.group(1) #store the desc as the concatination of the two error ones\n",
    "                new_rec['Description'] = desc_line #put in the tag desc in dictionary\n",
    "    \n",
    "    #when tag is of related terms then create a new sub dictionary by the key RelatedTerms to store its title and relationship\n",
    "    elif '<RelatedTerms>' in line:\n",
    "        new_rec['RelatedTerms'] = [{}]\n",
    "        sub_dic = True\n",
    "        continue\n",
    "        \n",
    "    #if related term tag ends check the sub dic as false\n",
    "    elif '</RelatedTerms>' in line:\n",
    "        sub_dic = False        \n",
    "    \n",
    "    elif '<Relationship>' in line:\n",
    "        rec_rel_relationship = rel_relationship.match(line)\n",
    "        new_rec['RelatedTerms'][0]['Relationship'] = rec_rel_relationship.group(1) #if tag is of relationship add it to related terms sub dic\n",
    "\n",
    "#once extracted close the file handle\n",
    "xml.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store json data in file\n",
    "file = json.dumps(dic)\n",
    "\n",
    "#create a new file and write to it (over write if already exists)\n",
    "fh = open(\"sport.dat\",\"w\")\n",
    "fh.write(file)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "Give a short summary of your work done above, such as your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the xml to json was somewhat of an easy task. the challanging part was not the cleaning or the formating. Since both the file formats are similar. \n",
    "\n",
    "The challenging part was identifying how the data should finally be stored in json. Also to identify the pattern in order to make the regexes as well as the if statements to tell the code what to do in what scenario. \n",
    "\n",
    "One of the issues faced was that all of the elements were in seperate but enclosed in one line when the file was read in except for one specific description tag. For this a two new regexes had to be created to extract the text from multiple lines and concatinate them before finally storing them in the correct format for the json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
